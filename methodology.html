<!DOCTYPE html>
<html lang="en">
<title>Methodology</title>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Poppins" />
<link rel="stylesheet" href="stylesheet.css" />

<body>
  <!-- Sidebar/menu -->
  <nav class="w3-sidebar w3-green w3-collapse w3-top w3-large w3-padding" style="
        z-index: 3;
        width: 300px;
        font-weight: bold;
        background-color: green;
      " id="mySidebar">
    <br />
    <div class="w3-container">
      <h3 class="w3-padding-64">
        <b>HCI<br />Taniwaka</b>
      </h3>
    </div>
    <div class="w3-bar-block">
      <a href="index.html">
        <h4>Home</h4>
      </a>
      <a href="methodology.html">
        <h4>Methodology</h4>
      </a>
      <a href="results.html">
        <h4>Results</h4>
      </a>
      <a href="discussion.html">
        <h4>Discussion</h4>
      </a>
      <a href="reflections.html">
        <h4>Reflections</h4>
      </a>
    </div>
  </nav>

  <!-- !PAGE CONTENT! -->
  <div class="w3-main" style="margin-left: 340px; margin-right: 40px">
    <!-- Header -->
    <div class="w3-container" style="margin-top: 80px">
      <h1 class="w3-jumbo"><b>Methodology</b></h1>
      <hr style="width: 50px; border: 5px solid green" class="w3-round" />
      <h2>Introduction</h2>
      <p>
        The study method that we chose for this assignment is the usability study. We chose this study because as future 
        software developers we want to understand and learn how usability studies are conducted when releasing a software 
        application in order to receive feedback from users. Through our usability study, we want to find the pros and cons 
        of an application, and if there are any improvements or new features a participant would like to see. Upon collecting 
        our findings, we will be comparing the similarities between the findings of each participant in order to identify 
        the bad features in the application that needs further improvements and possible new features that can be implemented into 
        the application. By conducting this study, we will have sufficent number of usability issues we have found in the application
        and with this information we can inform the developers of this application to improve the applications using the data we have
        provided to them. 
      </p>
      <h2>Research</h2>
      <P>
        Our methodology for the usability testing, was largely based off a paper from Phil Carter (Carter, 2007). In
        this paper Carter outlines a methodology that focusses on exploratory research. Traditional study methods
        such as collecting data from surveys and questionnaire which are usually reflective or a Cognitive Walkthrough
        which is more focussed on the design of the application (Wharton et al, 1994). The issues with these traditional study methodologies
        is that
        the user operates under a framework determined solely determined by the questioners, i.e. the questioners will
        ask them questions and. In a usability test the user will operate
        under their own framework rather than the testers'. Usability testing focusses on inquiring the user's experience
        of an application, while the user is using the application.
      </P>

      <p>
        <b>Talk about the difference between Cognitive Walkthrough and Usability testing by using Carter's table - Millan</b>
      </p>

      <p>
        <table class="table">
          <tr>
            <th></th>
            <th>Questionaire</th>
            <th>Interview</th>
            <th>Heuristic evaluation</th>
            <th>Cognitive walkthrough</th>
            <th>Usability testing</th>
          </tr>
          <tr>
            <td>Time</td>
            <td>No</td>
            <td>No</td>
            <td>Yes</td>
            <td>Yes</td>
            <td>Yes</td>
          </tr>
          <tr>
            <td>Time</td>
            <td>No</td>
            <td>No</td>
            <td>Yes</td>
            <td>Yes</td>
            <td>Yes</td>
          </tr>
          <tr>
            <td>Place</td>
            <td>No</td>
            <td>No</td>
            <td>No</td>
            <td>No</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Artifact (as primary focus)</td>
            <td>No</td>
            <td>No</td>
            <td>No</td>
            <td>Yes</td>
            <td>Yes</td>
          </tr>
          <tr>
            <td>User</td>
            <td>Yes</td>
            <td>Yes</td>
            <td>No</td>
            <td>No</td>
            <td>Yes</td>
          </tr>
          <tr>
            <td>User's cognitive framework</td>
            <td>No</td>
            <td>Yes</td>
            <td>No</td>
            <td>No</td>
            <td>Yes</td>
          </tr>
        </table>
        <h5 style="text-align: center;">
          <b>
          Table 1: Inquiring into the actual use of an artifact: are these methods typically done to the conditions of use? (Carter, 2007)
        </b>
        </h5>
      </p>

      <p>
        <b>Add carters moderator rules from the Usability bullet point - Millans.</b>
      </p>

      <P>
        One of the key techniques used in Carter's study methodology, is the <em>Talk aloud</em> or  <em>Think Aloud</em> technique. 
        This technique is a fast-paced technique that involves the participant to voice their thoughts, opinions, confusions while 
        they are using the application. According to Monique W.M. Jaspers et al. (2004), by recording the participant while they 
        interact with the application will allow researchers to further analyses the participant’s behavior through the video recording. 
        By doing so, evaluators can assess the participants reasoning in using the application and find the source of their problems 
        when they are using the system’s interface. The study by Norgaard M. Hornbaek K. (2006), suggests that some cases of using the 
        think aloud testing method might not get sufficiently analyzed. This is because the think aloud method is a fast-paced 
        technique and allow evaluators limited amount of time to note the participant’s reasoning. By video recording the sessions, 
        evaluators will have the ability thoroughly analyze and re-evaluate the participants reasonings of certain problems that’s in 
        the application. 
      </P>
      
      <p>
        According to the study by Kaikkonen, A, et el (2005), usability tests are typically done in a laboratory environment because cost and time to 
        conduct field testing is significantly more than one that is conducted in a laboratory environment. As shown in Table 2 that is from the same study, the 
        time to conduct the usability test in a laboratory environment is estimated to be 45 minutes while conducting a usability study using field 
        testing is estimated to be 1 hour and 45 minutes which is almost twice as long as testing in a laboratory setting. The time difference 
        between the two settings are quite significant due to the travel time for test moderators, longer time to set up equipment in a busy area, 
        and the difficulty of a tasks that is being done by the participant. This is interesting because according to this study, field tested participants would 
        move to the side of the pedestrian if a task was confusing in order to focus their concentration to complete the task due to the distractions 
        from the noise around them. Although this increased the testing time, but it did not impact the results of the feedback given from the participant as 
        the feedback recieved from participants that conducted their tests in a laboratory and field are quite similar. Through this study, they were able to 
        conclude that laboratory usability testing  provides sufficent amount of information to improve the user inferface and interaction of a system in 
        comparision to field usability testing. 
      </p>

      <p >
        <table class="table">
          <tr>
            <th>Place</th>
            <th>Total testing time (average)</th>
            <th>Instructions and preparations (estimate)</th>
            <th>Travel time for test moderator (estimate)</th>
          </tr>
          <tr>
            <td>Laboratory</td>
            <td>35 minutes</td>
            <td>10 minutes</td>
            <td>-</td>
          </tr>
          <tr>
            <td>Field</td>
            <td>45 minutes</td>
            <td>20 minutes</td>
            <td>40 minutes</td>
          </tr>
        </table>
        <h5 style="text-align: center;">
          <b>
          Table 2: Test times (Kaikkonen, A, et el, 2005)
          </b>
        </h5>
      </p>

      <p>
        Virzi (1992) have published articles on the topic of sample size in usability testing. Zirzi's study made three claims regarding sample size for 
        usability studies: (1) Observing four or five participants allows practitioners to discover 80% of a product's usability prblems, (2) observing 
        additional participants reveals fewer and fewer new usability problems, and (3) observers detect the more severe usability problems with the first 
        few participants. Based on these data, he claimed that running tests using small samples in an iterative test-and-design fashion would identify 
        most usability problems and save both time and money. 
      </p>
      
      <p>
        <b>Session times paragraph - Anua</b>
      </p>
      
      <p>
        <b>Why we chose Quantitive rather than Qualitive</b> <b>Michael</b><br>
        In this study, qualitative data is collected to focus on users' individual experiences and exploration using the
        cognitive walkthrough practice. In contrast, using quantitative data involves categorising usability problems into
        discrete categories and adopting statistical approaches to analyse data. A study by González et al. (2009) looked at
        the differences between using qualitative and a quantative approach, and their study found that quantative data lacks
        descriptive information which reveals individual usability problems, hence it is much more valuable to collect
        qualitative information for a user exploration study.
      </p>
      
      <p>
        <b>Why let participant exploring the app freely</b> <b>Michael</b><br>
        The users were not given any initial direction and were tasked to explore the app as they see fit. This practice
        utilises the theory of CE+ which was first proposed by Polson and Lewis (1990) and has since been established as the
        theoretical basis for many works in human-computer interaction. The CE+ model has four basic steps:<br>
      
      <ol type="1">
        <li>The user sets a goal to achieve in the interface.</li>
        <li>The user searches the interfaces to look for what actions are available.</li>
        <li>The user performs the action that they believe is mostly likely to achieve the goal they have set.</li>
        <li>The system provides feedback and the user analyses this to deduce whether or not they have made progress towards
          their goal.</li>
      </ol>
      
      The goal of usability for a system is one that is designed so that minimial learning is required to use the
      system, hence allowing participants to explore the application first implements CE+ theory and tests usability to its
      maximum without any external help.
      </p>
      
      <p>
        The article by M. Alshamari and P. Mayhew (2008), examined two task designs to find if these designs will influence the result in data collected in a usability test. 
        These two task designs are the <em>structured tasks</em> and <em>uncertain tasks</em>. Structured tasks are tasks that include step-by-step instructions on how 
        to perform a task. Uncertain tasks are tasks that relies on a fact which is that users are usually uncertain as to whether they will find the information that they 
        are looking for while using a feature. This article concludes that using task design in usability testing can influence the results, in both ways, negatively and 
        positively due to its variables and their roles. Structured tasks appeared to reveal most of the minor and superficial problems which directly connected to the 
        given guidelines and instructions, whereas uncertain tasks did not seem to discover so many minor and superficial problems but did better in the usability disaster 
        and major problems.
      </p>

      <h2>Usability</h2>
      <p>
        The usability study we conducted is on a meal tracking Android application. The purpose of this application is to allow 
        users the ability to record the food that they have eaten during the day, so that they are able to view and track the 
        nutrients that they have consumed for the day. The purpose of this usability study is to identify the flaws within the application 
        that is hard to use (not user friendly), reasonings to these flaws in order to improve it, and future features that can be implemented 
        to enhance the usability of the application.
      </p>
      <p>
        After anaylsing the comparision between Cognitive Walkthrough and Usability Testing from the paper by Phil Carter (2007),
        we have decided to conduct our usability study using usability testing. This is because our study will be a exploratory 
        study where participants will explore and identify various factors within a feature that may have flaws that can be further improved. Because 
        of the nature of our study, we will be collecting qualatative data instead of quantative data such as not using questionnaires 
        by observing the behaviour of our participants while they use the application and not down the reasonings to the problems. <br>
        <b>TALK MORE ABOUT Qualitive data vs Quantitive</b>
      </p>
      <p>
        As suggested by the study by Zirzi (1992), the ideal number of participants for a usability test is 4 or 5 test users. Therefore, we have 
        invited 4 participants to partake in our study. Our participants mainly consists of individuals that have experience in developing software
        which allowed us to recieve constructive feedback regarding bad layout designs and bad implementations in features. Due to the pandemic, 
        we decided to conduct our usbaility study virtually by using usbaility testing in a laboratory setting to ensure the safety of our researchers and 
        participants. Our other reason to why we chose to conduct our study in a laboratory setting is because the cost and time to conduct a usability 
        study using field testing is significantly more than one that is conducted in a laboratory environment (Kaikkonen, A, et el, 2005). We used the collaboration app, 
        Microsoft Teams, to conduct our usability tests with our participants. To avoid confusion when asking questions and instructing the participant, we assigned 
        one moderator for each usability test. This limits the number of people talking while allowing the remaining moderators to focus on observing the particpant and 
        taking notes of the problems that the participant is facing. 
      </p>
      <p>
        The concerns that we had when planning our usability tests was the amount of influence moderator can impact a participant's user 
        experience and the tools that will allow us to sufficently analyze our data. In order to limit the amount of influence a moderator 
        can impact the participant's user experience, we created rules for the moderator to follow during the testing session. 
        <b>TALK MORE ABOUT Carter's moderator rules here (Millan)</b> 
      </p>
      <p>
        Our other issue was first presented to us after reading the study by Norgaard M. Hornbaek K. (2006). This study has found that the information collected 
        by usability studies that use the think aloud method does not get sufficently analysed by moderator. To resolve this issue we decided to implement two recording methods which are 
        <em>test session recording</em> (recording the audio and facial expressions of our participant) and <em>screen recording</em> (recording the participants mobile device). With these two recording methods, we 
        are able to analyse participants facial expressions by reviewing the test session recording and correlate these expression with the the problem they 
        are experiencing with a feature by reviewing the screen recording. We are also able to identify problems that we have missed and we were also able to correct certain reasonings to 
        a problem when we have misunderstood the participant due to the fast-paced nature of a usability test.  
      </p>
      <p>
        During the testing of the application, we incorporated both design tasks and exploration method when the participant is testing the application.
        The reason why we chose an exploration method is because... <b>TALK ABOUT EXPLORING APP MICHAEL</b>. <br>
      </p>
      <p>
        As the article by M. Alshamari and P. Mayhew (2008) found that structured tasks and uncertain tasks both comes with their positive and negative impacts with 
        using these task designs in a usability test. Therefore, we decided to implement both tasks within our usability tests to discover both minor and major problems. 
        The structured task that we created was for the participant to add a new food record into the application’s database. Our structure task is to test the usabiliy of 
        inserting a new food record that is not in the database such as family recipes that the user likes to make. The uncertain task that we created was for the participant 
        to search for items that we have provided them and insert the found item into their daily food records (what they have consumed for the day). This task is to test the 
        usability of the search feature and the feature to insert foods that the user ate for the day. Throughout these tasks that are given to particpants, moderators has to 
        ensure that they are obliging to the moderator rules that we have set as mentioned above. 
        
        <br>The instructions for our structured task are:<br>
        <ol>
          <li>Locate the Add New Food Record on the main menu</li> 
          <li>Input random values into the add food records page</li> 
          <li>Once values are inserted, add the new food record.</li>
        </ol> 
        
        The instructions for our uncertain task are:<br>
        <ol>
          <li>Locate the a Search for Food Record menu on the main menu</li> 
          <li>Search for an egg</li> 
          <li>Add the found item into your Daily Food Records</li>
        </ol> 
      </p>

      <p>
        <b>Talk about how we implemented Session times here - Anua</b>
      </p>


      <br>
      <br>
      <br>
      <br>

      <h5><b>Things to do:</b></h5>
      <p>
        <li>
          Carter's moderator rules:
          <ol>
            <li>Carter, no influence to participants. No forcing opinions onto participant that will alter the data.</li>
            <li>Carter, getting confirmation of the problems and issues they are having.</li>
            <li>Carter, never say the participant is wrong </li>
            <li>Carter, listen carefully of the questions are asked for you</li>
            <li>Carter, keep questions simple and intent, no jargon. </li>
            <li>Carter, ask why a lot </li>
            <li>Carter, investigate mistakes </li>
            <li>Carter, probe nonverbal cues, observe their behaviour </li>
            <li>Carter, think aloud</li>
            <li>Carter, not having a commanding tone of moderators towards sessions, friendly tone.</li>
          </ol>
        </li>
        <li><b>Articles to Prove</b> Made sure that our sessions were conducted during the morning to afternoon to ensure that the participants are aware.</li>
        <li><b>Articles to Prove</b> Why we did not collect Quantitive data instead we collected Qualitive data as we are conducting a usability study which is exploratory. </li>
        <li><b>Articles to Prove</b> Allow paritipants to explore that application first, what benefits this does</li>
        <li><b>Articles to Prove</b> Give participants tasks to do to test specific features of the app, Adding food record. what benefits this does </li>

      <ul class="ref-apa">
        <h2>References</h2>
        <li>Carter, Phil., 2007. Liberating usability testing. <em>Interactions.</em> 14. 18-22.
          DOI: 10.1145/1229863.1229864.
        </li>
        <li>
          Wharton, C., Rieman, J., Lewis, C. and Polson, P., 1994. The Cognitive Walkthrough Method : A Practitioner's
          Guide. <em>In Usability Inspection Methods. </em>
        </li>
        <li>
          Monique W.M., Jaspers, Thiemo Steen, Cor van den Bos, Maud Geenen, 2004. 
          <a href="https://www.sciencedirect.com/science/article/pii/S1386505604001820?casa_token=b81h8sE54l0AAAAA:JrWqMXmViGQiQA1-B515mGXg2nwqFRvxA_6DWRdZhHMybYA2jmXNxynqRf3FR9xkps69NeP-EkY"> 
            International Journal of Medical Informatics :
            <em>The think aloud method: a guide to user interface design</em><br>
          </a>
        </li>
        <li>
          Norgaard, M., & Hornbaek, K., 2006. 
          <a href="https://dl.acm.org/doi/abs/10.1145/1142405.1142439?casa_token=h5ML_mbbiPEAAAAA%3AjuntseAWh2jz75fVccIERsBjU41VnqUuUgt5fX4iIIVIyR1M8G0fu12U60WHt2DJZBZoKTThJ0tysA"> 
            What do usability evaluators do in practice? :
            <em>an explorative study of think-aloud testing</em><br>
          </a>
        </li>
        <li>
          Kaikkonen, A, Kallio, T, Kekalainen, A, Kankainen, A, Canker, M., 2005. 
          <a href="http://lib.tkk.fi/Diss/2009/isbn9789522481900/article6.pdf"> 
            Usability Testing of Mobile Applications :
            <em>A Comparison between Laboratory and Field Testing</em><br>
          </a>
        </li>
        <li>
          González, M., Masip, L., Granollers, A., & Oliva, M., 2009. 
          <a href="https://doi.org/10.1016/j.advengsoft.2009.01.027"> 
            Quantitative analysis in a heuristic evaluation experiment.
            <em>Advances In Engineering Software, 40(12), 1271-1278.</em><br>
          </a>
        </li>
        <li>
          Polson, P., & Lewis, C., 1990. 
          <a href="https://doi.org/10.1207/s15327051hci0502&3_3"> 
            Theory-Based Design for Easily Learned Interfaces.
            <em>Human-Computer Interaction, 5(2), 191-220.</em><br>
          </a>
        </li>
        <li>
          Virzi, R. A., 1992. 
          <a href="https://journals.sagepub.com/doi/pdf/10.1177/001872089203400407"> 
            Why and when five test users aren’t enough. In Vanderdonckt, J., Blandford, A. and Derycke A. (eds.)
            <em>Proceedings of IHM-HCI 2001 Conference, Vol. 2 (Toulouse, France: Cépadèus Éditions), pp. 105-108.</em><br>
          </a>
        </li>
        <li>
          M. Alshamari and P. Mayhew,. 2008.
          <a href="https://ieeexplore.ieee.org/abstract/document/4545676?casa_token=8cvy_Y2ITx4AAAAA:_aHJRuaFGphoGlrTWoNJD7bfHwBCIpz6ZBDg8USp9nLMKGd38UHXyi6f9g2dMH36T7vnLKXm-2w"> 
            Task Design: Its Impact on Usability Testing," 2008
            <em>Third International Conference on Internet and Web Applications and Services, Athens, 2008, pp. 583-589, doi: 10.1109/ICIW.2008.20.</em><br>
          </a>
        </li>
      </ul>
    </div>
    <!-- End page content -->
  </div>
</body>

</html>